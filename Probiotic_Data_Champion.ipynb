{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFXwEyLVCQS44DAFqvGcVO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KondaCharana/DataExtraction-NLP/blob/main/Probiotic_Data_Champion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# Function to extract the title and main text from an HTML page\n",
        "def extract_article_text(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)  # Add headers\n",
        "        if response.status_code != 200:\n",
        "            return None, f\"Error: Received status code {response.status_code}\"\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract title\n",
        "        title_tag = soup.find('title')\n",
        "        title = title_tag.get_text(strip=True) if title_tag else 'No Title'\n",
        "\n",
        "        # Extract main content\n",
        "        article_body = soup.find(['article', 'main'])  # Look for <article> or <main>\n",
        "        if not article_body:\n",
        "            article_body = soup.find('div', {'class': 'content'})  # Try a common div class\n",
        "        if not article_body:\n",
        "            paragraphs = soup.find_all('p')  # Fallback to paragraphs\n",
        "            main_text = \"\\n\".join([p.get_text(strip=True) for p in paragraphs])\n",
        "        else:\n",
        "            main_text = article_body.get_text(\"\\n\", strip=True)\n",
        "\n",
        "        return title, main_text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return None, str(e)\n",
        "\n",
        "# Load the Excel file\n",
        "input_file = 'Book1.xlsx'  # Ensure the file exists\n",
        "data = pd.read_excel(input_file)\n",
        "\n",
        "# Ensure the 'Website' column contains properly formatted URLs\n",
        "def fix_url(url):\n",
        "    if url.startswith('www.'):\n",
        "        return 'https://' + url\n",
        "    elif not url.startswith(('http://', 'https://')):\n",
        "        return 'https://' + url  # Assume https if missing\n",
        "    return url\n",
        "\n",
        "data['Website'] = data['Website'].apply(fix_url)\n",
        "\n",
        "# Ensure output directory exists\n",
        "output_directory = 'Output'\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Extract and save article text for each company\n",
        "for index, row in data.iterrows():\n",
        "    company_name = row['Company Name']\n",
        "    url = row['Website']\n",
        "\n",
        "    title, main_text = extract_article_text(url)\n",
        "\n",
        "    if main_text and \"Error\" not in main_text:\n",
        "        output_file_path = os.path.join(output_directory, f\"{company_name.replace(' ', '_')}.txt\")\n",
        "        with open(output_file_path, 'w', encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Title: {title}\\n\\n{main_text}\")\n",
        "\n",
        "        print(f\"Extracted data for {company_name} from URL: {url}\")\n",
        "    else:\n",
        "        print(f\"Failed to extract data for {company_name} from URL: {url}. Error: {main_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n01-TnHnHKuJ",
        "outputId": "aff8ce10-fcf2-4c5f-e3e6-664b4b72f3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to extract data for Nestle from URL: https://www.nestle.com. Error: Error: Received status code 403\n",
            "Failed to extract data for Dr. Reddy's Laboratories from URL: https://www.drreddys.com. Error: \n",
            "Extracted data for Coca from URL: https://colacompany.com\n",
            "Extracted data for Pfizer from URL: https://www.pfizer.com\n",
            "Extracted data for PepsiCo from URL: https://www.pepsico.com\n",
            "Extracted data for Johnson & Johnson from URL: https://www.jnj.com\n",
            "Extracted data for Danone from URL: https://www.danone.com\n",
            "Failed to extract data for Bayer from URL: https://www.bayer.com. Error: Error: Received status code 403\n",
            "Extracted data for General Mills from URL: https://www.generalmills.com\n",
            "Extracted data for GlaxoSmithKline (GSK) from URL: https://www.gsk.com\n",
            "Extracted data for Kelloggâ€™s from URL: https://www.kelloggs.com\n",
            "Extracted data for Merck & Co. from URL: https://www.merck.com\n",
            "Extracted data for Unilever from URL: https://www.unilever.com\n",
            "Extracted data for Roche from URL: https://www.roche.com\n",
            "Failed to extract data for Nestle Waters from URL: https://www.nestlewaters.com. Error: Error: Received status code 403\n",
            "Extracted data for Sanofi from URL: https://www.sanofi.com\n",
            "Extracted data for Mondelez International from URL: https://www.mondelezinternational.com\n",
            "Extracted data for Novartis from URL: https://www.novartis.com\n",
            "Extracted data for Kraft Heinz from URL: https://www.kraftheinzcompany.com\n",
            "Failed to extract data for Eli Lilly and Company from URL: https://www.lilly.com. Error: Error: Received status code 403\n",
            "Extracted data for Tyson Foods from URL: https://www.tysonfoods.com\n",
            "Failed to extract data for Teva Pharmaceuticals from URL: https://www.tevapharm.com. Error: Error: Received status code 403\n",
            "Extracted data for Mars, Incorporated from URL: https://www.mars.com\n",
            "Failed to extract data for AbbVie from URL: https://www.abbvie.com. Error: Error: Received status code 403\n",
            "Extracted data for Campbell Soup Company from URL: https://www.campbellsoupcompany.com\n",
            "Extracted data for Amgen from URL: https://www.amgen.com\n",
            "Failed to extract data for Conagra Brands from URL: https://www.conagrabrands.com. Error: Error: Received status code 403\n",
            "Extracted data for AstraZeneca from URL: https://www.astrazeneca.com\n",
            "Extracted data for Molson Coors from URL: https://www.molsoncoors.com\n",
            "Failed to extract data for Boehringer Ingelheim from URL: https://www.boehringeringelheim.com. Error: \n",
            "Extracted data for AB InBev from URL: https://www.abinbev.com\n",
            "Extracted data for BASF from URL: https://www.basf.com\n",
            "Extracted data for Diageo from URL: https://www.diageo.com\n",
            "Extracted data for Procter & Gamble (P&G) from URL: https://www.pg.com\n",
            "Extracted data for Heineken from URL: https://www.theheinekencompany.com\n",
            "Extracted data for Medtronic from URL: https://www.medtronic.com\n",
            "Extracted data for McKesson from URL: https://www.mckesson.com\n",
            "Extracted data for AmerisourceBergen from URL: https://www.amerisourcebergen.com\n",
            "Extracted data for Cardinal Health from URL: https://www.cardinalhealth.com\n",
            "Failed to extract data for Medline Industries from URL: https://www.medline.com. Error: Error: Received status code 403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QXOGsHvHq4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define your keywords\n",
        "keywords = {\n",
        "    \"F&B\": [\"food\", \"beverage\", \"nutrition\", \"edible\", \"fortified\", \"grocery\", \"milk\", \"cereal\", \"pasta\", \"bakery\", \"juice\",\n",
        "            \"probiotic\", \"health drink\", \"energy drink\", \"dairy\", \"confectionery\", \"fermented\", \"snacks\", \"gut health\"],\n",
        "\n",
        "    \"Manufacturer\": [\"manufacture\", \"production\", \"factory\", \"processing\", \"ISO\", \"GMP\", \"FDA-approved\", \"bulk processing\",\n",
        "                     \"dosage form\", \"contract manufacturer\", \"plant certification\", \"ISO 9001\", \"USP standard\", \"formulations\"],\n",
        "\n",
        "    \"Brand\": [\"brand\", \"product line\", \"trademark\", \"buy\", \"purchase\", \"retail\", \"e-commerce\", \"pricing\", \"gut health\",\n",
        "              \"women's health\", \"sports nutrition\", \"mental wellness\", \"cognitive health\", \"pharmacy brand\"],\n",
        "\n",
        "    \"Distributor\": [\"wholesaler\", \"reseller\", \"supplier\", \"import\", \"export\", \"logistics\", \"supply chain\", \"procurement\",\n",
        "                    \"B2B supplier\", \"bulk raw materials\", \"nutraceutical distributor\", \"pharma distributor\"],\n",
        "\n",
        "    \"Bulk\": [\"pharma\", \"nutraceutical\", \"raw material\", \"strain\", \"bacteria\", \"bacillus coagulans\", \"saccharomyces\",\n",
        "             \"bulk customer\", \"ingredient supplier\", \"probiotic blends\", \"contract manufacturing\"],\n",
        "\n",
        "    \"Health Segment\": [\"gut health\", \"women's health\", \"cognitive health\", \"mental wellness\", \"sports nutrition\",\n",
        "                       \"digestive health\", \"PCOD\", \"UTI\", \"Bacipro\", \"Provinorm\", \"Cognisol\"]\n",
        "}\n",
        "\n",
        "# Load your Excel file\n",
        "excel_file = \"input.xlsx\"  # Replace with your Excel file name\n",
        "df = pd.read_excel(excel_file)\n",
        "\n",
        "# Add new columns and initialize with \"no\"\n",
        "for category in keywords:\n",
        "    df[category] = \"no\"\n",
        "\n",
        "# Process each company\n",
        "'''\n",
        "for index, row in df.iterrows():\n",
        "    company_name = row['Company Name']\n",
        "    text_file_path = os.path.join(\"Output\", f\"{company_name}.txt\")  # Assuming text files are in \"Output\" folder\n",
        "\n",
        "    try:\n",
        "        with open(text_file_path, 'r') as f:\n",
        "            text = f.read().lower()  # Read and convert to lowercase for case-insensitive matching\n",
        "\n",
        "            # Check for keywords and update Excel columns\n",
        "            for category, keyword_list in keywords.items():\n",
        "                if any(keyword in text for keyword in keyword_list):\n",
        "                    df.loc[index, category] = \"yes\"\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Text file not found for {company_name}\")\n",
        "'''\n",
        "for index, row in df.iterrows():\n",
        "    company_name = row['Company Name']\n",
        "    text_file_path = os.path.join(\"Output\", f\"{company_name}.txt\")  # Assuming text files are in \"Output\" folder\n",
        "\n",
        "    try:\n",
        "        with open(text_file_path, 'r') as f:\n",
        "            text = f.read().lower()  # Read and convert to lowercase for case-insensitive matching\n",
        "\n",
        "            found = False  # Track if any keyword is found\n",
        "            for category, keyword_list in keywords.items():\n",
        "                if any(keyword in text for keyword in keyword_list):\n",
        "                    df.loc[index, category] = \"Yes\"\n",
        "                    found = True\n",
        "\n",
        "            # If no keyword matched, mark all categories as \"Not Relevant\"\n",
        "            if not found:\n",
        "                for category in keywords:\n",
        "                    df.loc[index, category] = \"Not Relevant\"\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Text file not found for {company_name}\")\n",
        "# Save the updated Excel file\n",
        "df.to_excel(\"output.xlsx\", index=False)  # Replace with desired output file name\n",
        "print(\"Keywords checked and Excel file updated successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdmLHSlXHrDC",
        "outputId": "e760edfd-15ca-4448-e961-a2ddf973de74"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text file not found for Dr. Reddy's Laboratories\n",
            "Text file not found for Boehringer Ingelheim\n",
            "Keywords checked and Excel file updated successfully.\n"
          ]
        }
      ]
    }
  ]
}